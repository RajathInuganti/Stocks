{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43028770",
   "metadata": {
    "id": "43028770"
   },
   "source": [
    "# Name: Rajath Inuganti\n",
    "# V-No: V00874612"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f81d5294",
   "metadata": {
    "id": "f81d5294"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from scipy.special import expit, softmax\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QJmh8Ju5HE3N",
   "metadata": {
    "id": "QJmh8Ju5HE3N"
   },
   "source": [
    "**Note**: I have relied on the Textbook and the https://machinelearningmastery.com/ website as a reference for completing this question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UMMmPrILy9AG",
   "metadata": {
    "id": "UMMmPrILy9AG"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yvWIwFYWL_Hp",
   "metadata": {
    "id": "yvWIwFYWL_Hp"
   },
   "source": [
    "Note: I was the one who posted the question titled \"Problem 1 Part 1\" on Piazza (question @143), so I will be using the same.\n",
    "\n",
    "In the Textbook (Pg 102), the gradient used to update a weight from unit $i$ into unit $j$, $w_{ji}$, for backpropagation is derived using the equation:\n",
    "\n",
    "$\\frac{\\partial E_{d}}{\\partial w_{ji}}$ = $\\frac{\\partial E_{d}}{\\partial net_{j}}$ $\\frac{\\partial net_{j}}{\\partial w_{ji}}$\n",
    "\n",
    "where, $\\frac{\\partial E_{d}}{\\partial net_{j}}$ = $\\frac{\\partial E_{d}}{\\partial o_{j}}$ $\\frac{\\partial o_{j}}{\\partial net_{j}}$\n",
    "\n",
    "Here, $o_{j}$ is the output calculated using the softmax function (instead of the sigmoid function). So, I suppose we are interested in deriving $f(x)_{i}$ w.r.t $x$, which is the $net_{j}$ in the equation, where $net_{j}$ is $W^TX$: the linear output. So,\n",
    "\n",
    "$\\frac{\\partial o_{j}}{\\partial net_{j}}$ = $\\frac{\\partial f_{i}(x)}{\\partial x_{i}}$ = $\\frac{e^{x_{i}}\\sum_{j}e^{x_{j}} \\hspace{0.1cm} - \\hspace{0.1cm} e^{x_{i}}(e^{x_{i}})}{(\\sum_{j}e^{x_{j}})^2}$ = $\\frac{e^{x_{i}}}{\\sum_{j}e^{x_{j}}}$ - $(\\frac{e^{x_{i}}}{\\sum_{j}e^{x_{j}}})^2$ = $f_{i}(x) - (f_{i}(x))^2$; when $i$ = $j$\n",
    "\n",
    "when $i$ ≠ $j$ $\\frac{0\\sum_{j}e^{x_{j}} \\hspace{0.1cm} - \\hspace{0.1cm} e^{x_{j}}(e^{x_{i}})}{(\\sum_{j}e^{x_{j}})^2}$ = $\\frac{-e^{x_{j}}}{\\sum_{j}e^{x_{j}}}$ $\\frac{e^{x_{i}}}{\\sum_{j}e^{x_{j}}}$ = $-f_{j}(x)f_{i}(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_w8jvDyTJdTk",
   "metadata": {
    "id": "_w8jvDyTJdTk"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "j5PujLc-JiT9",
   "metadata": {
    "id": "j5PujLc-JiT9"
   },
   "outputs": [],
   "source": [
    "class ANN():\n",
    "\n",
    "  def __init__(self, sizes):\n",
    "    self.activations = []\n",
    "    self.biases = [np.random.uniform(low=-0.5, high=0.5, size=size) for size in sizes[1:]]\n",
    "    self.weights = [np.random.uniform(low=-0.5, high=0.5, size=(inputs, weights))\n",
    "                    for weights, inputs in zip(sizes[:-1], sizes[1:])]\n",
    "  \n",
    "  def train(self, x_train, y_train, num_iterations, learning_rate):\n",
    "    self.SGD(x_train, y_train, num_iterations, learning_rate)\n",
    "  \n",
    "  def SGD(self, x_train, y_train, num_iterations, learning_rate):\n",
    "    \"\"\"Based on the SGD Backpropagation algorithm in the TB\"\"\"\n",
    "\n",
    "    for index in range(num_iterations):\n",
    "      for input, target in zip(x_train, y_train):\n",
    "        self.activations.clear()\n",
    "        self.feedforward(input)\n",
    "\n",
    "        \"\"\"Calculating error terms for output layer\"\"\"\n",
    "        error_terms = []\n",
    "        \"\"\"CE_error_delta is the cross entropy derivative delta_softmax \n",
    "          is the softmax activation derivative for i = j and i ≠ j\"\"\"\n",
    "        layer_error_terms = np.asarray(self.activations[-1])\n",
    "        layer_error_terms[target] = layer_error_terms[target] - 1\n",
    "        error_terms.append(np.asarray(layer_error_terms.copy()))\n",
    "\n",
    "        \"\"\"Calculating error terms for the hidden layers\"\"\"\n",
    "        num_layers = len(self.activations)\n",
    "        for index, weight_matrix in enumerate(reversed(self.weights[1:])):\n",
    "          w_delta = weight_matrix * error_terms[-1][:, None]\n",
    "          w_delta_sum = np.sum(w_delta, axis=0)\n",
    "          activations = self.activations[num_layers - index - 2]\n",
    "          sigmoid_delta = ((activations * -1) + 1) * activations\n",
    "          error_terms.append(w_delta_sum * sigmoid_delta)\n",
    "\n",
    "        \"\"\"Updating weights & biases using numpy\"\"\"\n",
    "        for index, data in enumerate(zip(error_terms, reversed(self.weights))):\n",
    "          layer_error_terms, weight_matrix = data[0], data[1]\n",
    "          layer_error_terms = np.asarray(layer_error_terms)\n",
    "          layer_activations = self.activations[num_layers - index - 2]\n",
    "          layer_activations = np.tile(layer_activations, (len(layer_error_terms), 1))\n",
    "          delta_w = layer_activations * layer_error_terms[:, None]\n",
    "          delta_w = -1 * delta_w * learning_rate\n",
    "          weight_matrix = weight_matrix + delta_w\n",
    "          self.weights[len(self.weights) - index - 1] = np.copy(weight_matrix)\n",
    "          delta_bias = layer_error_terms * learning_rate\n",
    "          self.biases[len(self.biases) - index - 1] -= delta_bias\n",
    "\n",
    "\n",
    "  def feedforward(self, input):\n",
    "    self.activations.append(input)\n",
    "    for bias, weight in zip(self.biases[:-1], self.weights[:-1]):\n",
    "      input = np.dot(input, weight.T) + bias\n",
    "      input = self.sigmoid(input)\n",
    "      self.activations.append(input)\n",
    "    \"\"\"For the output layer: softmax\"\"\"\n",
    "    input = np.dot(input, self.weights[-1].T) + self.biases[-1]\n",
    "    softmax_vals = self.softmax(input)\n",
    "    self.activations.append(softmax_vals)\n",
    "\n",
    "  def evaluate(self, input):\n",
    "    self.activations.clear()\n",
    "    self.feedforward(input)\n",
    "    return np.argmax(self.activations[-1])\n",
    "\n",
    "  def sigmoid(self, input):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return expit(input)\n",
    "  \n",
    "  def softmax(self, input):\n",
    "    \"\"\"The softmax function.\"\"\"\n",
    "    return softmax(input)\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "kKvTcuZ2Jfxx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kKvTcuZ2Jfxx",
    "outputId": "8083a0e8-3f55-4788-8035-735d992280c4"
   },
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X, test_X = train_X/255, test_X/255\n",
    "train_X = np.asarray([input.flatten() for input in train_X])\n",
    "test_X = np.asarray([input.flatten() for input in test_X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "DBWp0VNVYX2l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBWp0VNVYX2l",
    "outputId": "03a7357c-eead-4896-9172-547cc737ed49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 37s, sys: 10.3 s, total: 11min 47s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "network = ANN(sizes=[784, 128, 10])\n",
    "network.train(train_X, train_y, 5, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "gdw5JQSbHgwH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdw5JQSbHgwH",
    "outputId": "9448feb1-cb43-4899-b1f1-88dd87eca4b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09863333333333334"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classifications = 0\n",
    "for input, target in zip(train_X, train_y):\n",
    "  prediction = network.evaluate(input)\n",
    "  if prediction == target:\n",
    "    correct_classifications += 1\n",
    "accuracy = correct_classifications/len(train_X)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bT56XYdhFyDl",
   "metadata": {
    "id": "bT56XYdhFyDl"
   },
   "source": [
    "I have found that my error is so low due to using squared error as a cost function, instead of categorical, crossentropy.\n",
    "I haven't used categorical cross-entropy as I was having divide by zero issues and overflows.\n",
    "My low accuracy is consistent with Keras when run using squared error as a cost metric, so it seems like my propagation is correct while only my cost function needs to change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HE-cwAuNw4bY",
   "metadata": {
    "id": "HE-cwAuNw4bY"
   },
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "K0MiWQiNwlxf",
   "metadata": {
    "id": "K0MiWQiNwlxf"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(units=128, input_shape=(784,), activation='sigmoid'))\n",
    "model1.add(Dense(units=10, activation='softmax'))\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "model1.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "Z7TGa-jtBPac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7TGa-jtBPac",
    "outputId": "bce30e24-3c98-4172-abd3-df16d1343a3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.0647 - accuracy: 0.7745\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4889 - accuracy: 0.8765\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3958 - accuracy: 0.8921\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3558 - accuracy: 0.9006\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3321 - accuracy: 0.9054\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3156 - accuracy: 0.9101\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3029 - accuracy: 0.9129\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2924 - accuracy: 0.9160\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2832 - accuracy: 0.9186\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2750 - accuracy: 0.9206\n",
      "CPU times: user 54.9 s, sys: 15.2 s, total: 1min 10s\n",
      "Wall time: 29.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbc2e33400>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model1.fit(x=train_X, y=to_categorical(train_y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X5PchvT_Hlvg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5PchvT_Hlvg",
    "outputId": "d1884007-9870-4ae1-a597-c54f1a669d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2643 - accuracy: 0.9249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9248999953269958"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = model1.evaluate(test_X, to_categorical(test_y))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VMAfBfVo8H06",
   "metadata": {
    "id": "VMAfBfVo8H06"
   },
   "source": [
    "Training happens much **Faster** when using Keras. \n",
    "\n",
    "Perhaps, This is due to the specific way they handled the matrix operations and floating point operations as this would depend on their specific implementation.\n",
    "\n",
    "The network also seems to be **Better** as it has > 90% accuracy by the time of the 4th epoch. This is probably due to the fact that I made Keras use categorical cross entropy instead of squared error (used in textbook). The accuracy drops to almost the same level of my implementation, if we use sqaured error instead for Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42HsBR0d9t09",
   "metadata": {
    "id": "42HsBR0d9t09"
   },
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vmpcg6mh9sND",
   "metadata": {
    "id": "vmpcg6mh9sND"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(units=128, input_shape=(784,), activation='relu'))\n",
    "model2.add(Dense(units=10, activation='softmax'))\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BELd63eY-Dv1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BELd63eY-Dv1",
    "outputId": "38837885-68d3-4366-9f5e-fdbdb791453e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4977 - accuracy: 0.8698\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2760 - accuracy: 0.9233\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2278 - accuracy: 0.9362\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1958 - accuracy: 0.9455\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1718 - accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1532 - accuracy: 0.9571\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1382 - accuracy: 0.9616\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1261 - accuracy: 0.9650\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9685\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1069 - accuracy: 0.9704\n",
      "CPU times: user 1min 13s, sys: 5.5 s, total: 1min 19s\n",
      "Wall time: 1min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a7295b950>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model2.fit(x=train_X, y=to_categorical(train_y), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vODKFmSbIr1w",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vODKFmSbIr1w",
    "outputId": "5995044f-23b0-4e0f-fac2-e30eefacc0de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1111 - accuracy: 0.9674\n",
      "CPU times: user 1.15 s, sys: 53.8 ms, total: 1.2 s\n",
      "Wall time: 1.49 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9674000144004822"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_, accuracy = model2.evaluate(test_X, to_categorical(test_y))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8jxs0BdtSWHB",
   "metadata": {
    "id": "8jxs0BdtSWHB"
   },
   "source": [
    "Using **Relu** results in an execution that isn't much faster than sigmoid.\n",
    "\n",
    "However, it does seem to be **better** as it looks like it generalizes better when it comes to the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5pnJTaOTL9h",
   "metadata": {
    "id": "a5pnJTaOTL9h"
   },
   "source": [
    "## Part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YDuvqt64TK4-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YDuvqt64TK4-",
    "outputId": "0095db9b-2259-4d38-8f14-acd428ed1e9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 3ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n",
      "375/375 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-742386de-b8d8-4c8d-8394-781061735446\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589783</td>\n",
       "      <td>0.042582</td>\n",
       "      <td>{'dropout': 0.2, 'epochs': 5, 'l2_val': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.402167</td>\n",
       "      <td>0.011618</td>\n",
       "      <td>{'dropout': 0.2, 'epochs': 5, 'l2_val': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104183</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>{'dropout': 0.2, 'epochs': 5, 'l2_val': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.361433</td>\n",
       "      <td>0.021694</td>\n",
       "      <td>{'dropout': 0.4, 'epochs': 5, 'l2_val': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.188283</td>\n",
       "      <td>0.053697</td>\n",
       "      <td>{'dropout': 0.4, 'epochs': 5, 'l2_val': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.103650</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>{'dropout': 0.4, 'epochs': 5, 'l2_val': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.123633</td>\n",
       "      <td>0.024086</td>\n",
       "      <td>{'dropout': 0.6, 'epochs': 5, 'l2_val': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.120850</td>\n",
       "      <td>0.044297</td>\n",
       "      <td>{'dropout': 0.6, 'epochs': 5, 'l2_val': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.108267</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>{'dropout': 0.6, 'epochs': 5, 'l2_val': 0.01}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>{'dropout': 0.8, 'epochs': 5, 'l2_val': 0.0001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.107467</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>{'dropout': 0.8, 'epochs': 5, 'l2_val': 0.001}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.106467</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>{'dropout': 0.8, 'epochs': 5, 'l2_val': 0.01}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742386de-b8d8-4c8d-8394-781061735446')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-742386de-b8d8-4c8d-8394-781061735446 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-742386de-b8d8-4c8d-8394-781061735446');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  \\\n",
       "0          0.589783        0.042582   \n",
       "1          0.402167        0.011618   \n",
       "2          0.104183        0.005953   \n",
       "3          0.361433        0.021694   \n",
       "4          0.188283        0.053697   \n",
       "5          0.103650        0.005085   \n",
       "6          0.123633        0.024086   \n",
       "7          0.120850        0.044297   \n",
       "8          0.108267        0.006584   \n",
       "9          0.112367        0.003342   \n",
       "10         0.107467        0.005693   \n",
       "11         0.106467        0.006526   \n",
       "\n",
       "                                             params  \n",
       "0   {'dropout': 0.2, 'epochs': 5, 'l2_val': 0.0001}  \n",
       "1    {'dropout': 0.2, 'epochs': 5, 'l2_val': 0.001}  \n",
       "2     {'dropout': 0.2, 'epochs': 5, 'l2_val': 0.01}  \n",
       "3   {'dropout': 0.4, 'epochs': 5, 'l2_val': 0.0001}  \n",
       "4    {'dropout': 0.4, 'epochs': 5, 'l2_val': 0.001}  \n",
       "5     {'dropout': 0.4, 'epochs': 5, 'l2_val': 0.01}  \n",
       "6   {'dropout': 0.6, 'epochs': 5, 'l2_val': 0.0001}  \n",
       "7    {'dropout': 0.6, 'epochs': 5, 'l2_val': 0.001}  \n",
       "8     {'dropout': 0.6, 'epochs': 5, 'l2_val': 0.01}  \n",
       "9   {'dropout': 0.8, 'epochs': 5, 'l2_val': 0.0001}  \n",
       "10   {'dropout': 0.8, 'epochs': 5, 'l2_val': 0.001}  \n",
       "11    {'dropout': 0.8, 'epochs': 5, 'l2_val': 0.01}  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def model_builder(l2_val, dropout):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(units=128, input_shape=(784,), activation='sigmoid', kernel_regularizer=regularizers.L2(l2_val)))\n",
    "  model.add(Dropout(dropout))\n",
    "  model.add(Dense(units=128, activation='sigmoid', kernel_regularizer=regularizers.L2(l2_val)))\n",
    "  model.add(Dropout(dropout))\n",
    "  model.add(Dense(units=128, activation='sigmoid', kernel_regularizer=regularizers.L2(l2_val)))\n",
    "  model.add(Dropout(dropout))\n",
    "  model.add(Dense(units=10, activation='softmax', kernel_regularizer=regularizers.L2(l2_val)))\n",
    "  optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "  model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "  return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=model_builder)\n",
    "param_grid = {'l2_val':[0.0001, 0.001, 0.01], 'dropout':[0.2, 0.4, 0.6, 0.8], 'epochs': [5]}\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "fit = grid.fit(train_X, train_y, verbose=0)\n",
    "pd.DataFrame(grid.cv_results_)[['mean_test_score', 'std_test_score', 'params']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pj4UCcIufYlm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pj4UCcIufYlm",
    "outputId": "0d693b2f-5bdc-442f-dda2-3395e35510c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3353 - accuracy: 0.1028\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3430 - accuracy: 0.1795\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3462 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3490 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.7142 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.7159 - accuracy: 0.2042\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.7141 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.7142 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.3925 - accuracy: 0.1032\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.3907 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.3846 - accuracy: 0.1135\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 3.3739 - accuracy: 0.0982\n",
      "Highest accuracy acheived with L2 Value: 0.001 and dropout value: 0.4\n"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "for l2_val in param_grid['l2_val']:\n",
    "  for dropout in param_grid['dropout']:\n",
    "    model = model_builder(l2_val, dropout)\n",
    "    model.fit(x=train_X, y=to_categorical(train_y), epochs=1, verbose=0)\n",
    "    _, accuracy = model.evaluate(test_X, to_categorical(test_y))\n",
    "    metrics = \"L2 Value: \" + str(l2_val) + \" and dropout value: \" + str(dropout)\n",
    "    accuracies[metrics] = accuracy\n",
    "\n",
    "print(\"Highest accuracy acheived with \" + max(accuracies, key=accuracies.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lL5ehXGCBn-S",
   "metadata": {
    "id": "lL5ehXGCBn-S"
   },
   "source": [
    "It seems that although training error is low for values for dropout 0.2 and l2 at 0.0001, the test error is lower in model with dropout 0.4 and l2 at 0.001.\n",
    "\n",
    "This might also be the case because of the fact that I retrained the model again and then evalaluated on the validation set. Still, however, the difference in the model might not have been super high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1AfOComZa",
   "metadata": {
    "id": "48b1AfOComZa"
   },
   "source": [
    "## Part 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EKzAv8OfNhcd",
   "metadata": {
    "id": "EKzAv8OfNhcd"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras import layers\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "train_X = train_X.reshape((train_X.shape[0], 28, 28, 1))\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Conv2D(32, kernel_size = (3,3), activation='sigmoid', input_shape = (28, 28,1)))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(Dense(units=128, activation='sigmoid'))\n",
    "model5.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "model5.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0doO_oLTpD2W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0doO_oLTpD2W",
    "outputId": "14adf499-00a8-4332-e3b8-157ca624f784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 12.2 µs\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.5944 - accuracy: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4a6b5ab650>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "model5.fit(train_X, to_categorical(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9L4-zc8lplfQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L4-zc8lplfQ",
    "outputId": "ea50fbd0-742e-4d6e-d4e4-55f14a93aabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 11.2 µs\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 2.3011 - accuracy: 0.1135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11349999904632568"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "_, accuracy = model5.evaluate(test_X, to_categorical(test_y))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KWHq3RhzDIK4",
   "metadata": {
    "id": "KWHq3RhzDIK4"
   },
   "source": [
    "Above in the code are the values I found to be best performing overall. There wasn't a significant improvement however. The model from the 4th question implemented using relu seems to be the best performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EwaEE83z5POd",
   "metadata": {
    "id": "EwaEE83z5POd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
